{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "보스턴 집값 데이터 문제3",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNw8/jV6htxIL4MvDzyqELY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chacha86/BigData3/blob/colab/%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A7%91%EA%B0%92_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%AC%B8%EC%A0%9C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrb3F0IIyKnb"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "from sklearn.datasets import load_boston\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore') # 경고무시\n",
        "\n",
        "# 보스턴 집값 데이터 로드\n",
        "bos = load_boston()\n",
        "\n",
        "# 보스턴 집값의 독립변수 데이터 배열\n",
        "data =  bos.data\n",
        "\n",
        "# 보스턴 집값(종속변수)\n",
        "target =  bos.target\n",
        "\n",
        "# 특성 이름\n",
        "feature_names = bos.feature_names\n",
        "\n",
        "df = pd.DataFrame(data, columns=feature_names)\n",
        "\n",
        "# CHAS: 찰스강에 대한 더미 변수(강의 경계에 위치한 경우는 1, 아니면 0)\n",
        "# NOX: 일산화질소 농도\n",
        "# RM: 거주할 수 있는 방 개수\n",
        "# AGE: 1940년 이전에 건축된 소유 주택의 비율\n",
        "# DIS: 5개 주요 고용센터까지의 가중 거리\n",
        "# RAD: 고속도로 접근 용이도\n",
        "# TAX: 10,000달러당 재산세\n",
        "# PTRATIO: 지역의 교사와 학생 수 비율\n",
        "# B: 지역의 흑인 거주 비율\n",
        "# LSTAT: 하위 계층의 비율\n",
        "\n",
        "# 문제1 -> 가장 상관관계가 높은 특성을 찾아서 최근접 이웃 회귀로 성능지표를 확인하고 집값을 예측해주세요\n",
        "# 시각화를 해주세요.\n",
        "# 힌트1 . 상관관계가 높다라는 것은 기울기가 크다라는 뜻\n",
        "# 힌트2 . 기울기를 직접 찾으려고 하면 안되고 모델에게 찾아달라고 해야함.\n",
        "# 힌트3 . 반복문을 이용해 subplots을 이용해서 시각화\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(df['CRIM'], target)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# plt.subplots()\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize = (10, 10))\n",
        "\n",
        "\n",
        "# 주기 표현\n",
        "\n",
        "\n",
        "coef_list = []\n",
        "\n",
        "i = 0\n",
        "for feature in df.columns.values :\n",
        "  col = i % 4\n",
        "  row = i // 4\n",
        "\n",
        "  trd = df[[feature]].values\n",
        "\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(trd, target)\n",
        "  lr.coef_, lr.intercept_ # ax + b \n",
        "  \n",
        "  coef_list.append(lr.coef_[0])\n",
        "\n",
        "  x_min = np.min(trd)\n",
        "  x_max = np.max(trd)\n",
        "\n",
        "  def get_price(x) :\n",
        "    return lr.coef_ * x + lr.intercept_\n",
        "\n",
        "  y_min = get_price(x_min)\n",
        "  y_max = get_price(x_max)\n",
        "\n",
        "  axes[row, col].scatter(trd, target) \n",
        "  axes[row, col].plot([x_min, x_max], [y_min, y_max])\n",
        "  axes[row, col].set_title(feature)\n",
        "  i += 1\n",
        "\n",
        "s = pd.Series(coef_list, index=df.columns)\n",
        "s.sort_values(ascending=False)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trd, tsd, trt, tst = train_test_split(df['RM'], target, random_state=40)\n",
        "\n",
        "trd = trd.values.reshape(-1, 1)\n",
        "tsd = tsd.values.reshape(-1, 1)\n",
        "knr = KNeighborsRegressor()\n",
        "knr.fit(trd, trt)\n",
        "knr.score(trd, trt), knr.score(tsd, tst)\n",
        "\n",
        "print(knr.predict([trd[0]]), trt[0])\n",
        "print(knr.predict([trd[7]]), trt[7])\n",
        "print(knr.predict([trd[10]]), trt[10])\n",
        "\n",
        "knr.predict([[400000000]])\n",
        "\n",
        "# 특성이 하나면, 제곱, 세제곱, 네제곱......\n",
        "\n",
        "# 문제2 -> 위에서 선택된 특성을 선형회귀 모델을 이용해 학습데이터 평가 점수 0.60, 테스트데이터 평가점수 0.55 이상으로 학습시켜주세요.\n",
        "# 힌트1 . 피쳐 엔지니어링을 이용해 정확도 높이기\n",
        "# 힌트2 . PolynomialFeatures 활용\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성이 하나면, 제곱, 세제곱, 네제곱......\n",
        "\n",
        "# 문제2 -> 위에서 선택된 특성을 선형회귀 모델을 이용해 학습데이터 평가 점수 0.60, 테스트데이터 평가점수 0.55 이상으로 학습시켜주세요.\n",
        "# 힌트1 . 피쳐 엔지니어링을 이용해 정확도 높이기\n",
        "# 힌트2 . PolynomialFeatures 활용\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(trd, trt)\n",
        "lr.score(trd, trt), lr.score(tsd, tst)\n",
        "\n",
        "# 과소적합 해소를 위해 \n",
        "# 과대적합, 과소적합을 소하는 방법\n",
        "# 과소적합 -> 특성(feature)를 추가하거나 ,회귀식의 0차수를 높인다.\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias = False)  # 기본 차수 -> 2차\n",
        "\n",
        "for i in range(1, 30) :\n",
        "  poly.degree = i\n",
        "  poly.fit(trd, trt)\n",
        "  poly.get_feature_names_out()\n",
        "  trd_poly = poly.transform(trd)\n",
        "  tsd_poly = poly.transform(tsd)\n",
        "  \n",
        "  lr.fit(trd_poly, trt) # trt \n",
        "  if  lr.score(trd_poly, trt) >= 0.60 and lr.score(tsd_poly, tst) >= 0.55 :\n",
        "    break\n",
        "\n",
        "print(lr.score(trd_poly, trt), lr.score(tsd_poly, tst))\n",
        "\n",
        "# 다항회귀 -> 특성을 늘리는 방식\n",
        "trd, tsd, trt, tst = train_test_split(df, target, random_state=44)\n",
        "\n",
        "poly.degree = 2\n",
        "poly.fit(trd, trt)\n",
        "poly.get_feature_names_out()\n",
        "trd_poly = poly.transform(trd)\n",
        "tsd_poly = poly.transform(tsd)\n",
        "\n",
        "lr.fit(trd_poly, trt)\n",
        "lr.score(trd_poly, trt), lr.score(tsd_poly, tst)\n",
        "\n"
      ],
      "metadata": {
        "id": "1A2Xf9xXI052"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oYJm4J86IybP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
